# Flood_Prediction_NLP

This collaborative project was conducted as part of the Data Science and Public Policy class at Columbia University. Our analysis heavily relied on datasets and project materials provided by Max Mauerman and Elizabeth Tellman.

Currently, the detection of extreme weather events employs a range of methodologies, including hydrological models, ground-based sensors, and satellite imagery. These methods, however, hinge on the availability of high-quality, long-term data collection and the infrastructure required for extensive monitoring.

Our research aims to explore the potential of Natural Language Processing (NLP) in predicting floods through the analysis of text-based data sources, such as news articles and social media platforms like Twitter. NLP probably could offer real-time insights into the location and possible intensity of flood events, thereby enhancing the efficiency and effectiveness of response measures.

The methodology of our data analysis includes:
1. Developing an NLP model to detect references to flooding within a dataset of news articles from Bangladesh, employing various algorithms for comparison:
- BERT (Bidirectional Encoder Representations from Transformers)
- Random Forest
- Linear Support Vector Classification (SVC)
- Logistic Regression with both L1 and L2 regularization

2. Evaluating the performance of our NLP model by comparing its predictions with external datasets, including satellite observations, to assess accuracy and reliability in real-world 

